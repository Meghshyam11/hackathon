{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11klXzEHMux0XgQXkwY6_GVBVO8tqYIZc","timestamp":1701796105301}],"authorship_tag":"ABX9TyMFj0yiod18000TVZM7CfJ1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"1J86fpYyw9yb"}},{"cell_type":"code","source":["# Import necessary libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Load the dataset\n","from google.colab import drive\n","\n","credit_card=drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kjzd23cJipTu","executionInfo":{"status":"ok","timestamp":1701792668057,"user_tz":-330,"elapsed":6667,"user":{"displayName":"meghshyam karpe","userId":"02298623278313287783"}},"outputId":"3e299d3c-9cbe-4b88-986c-254578e07391"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import pandas as pd\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Assuming your credit card dataset is stored in a file named 'credit_card.csv'\n","file_path = '/content/drive/My Drive/path/to/your/dataset/credit_card.csv'\n","\n","# Read the CSV file into a DataFrame\n","df = pd.read_csv('/content/creditcard.csv')\n","\n","# Display the head of the dataset\n","print(\"Head of the dataset:\")\n","print(df.head())\n","\n","# Display the tail of the dataset\n","print(\"\\nTail of the dataset:\")\n","print(df.tail())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUvQMRQFu_6u","executionInfo":{"status":"ok","timestamp":1701793404191,"user_tz":-330,"elapsed":6476,"user":{"displayName":"meghshyam karpe","userId":"02298623278313287783"}},"outputId":"4a403d42-4a3f-4b7b-ce2d-70a354c72fff"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Head of the dataset:\n","   Time        V1        V2        V3        V4        V5        V6        V7  \\\n","0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n","1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n","2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n","3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n","4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n","\n","         V8        V9  ...       V21       V22       V23       V24       V25  \\\n","0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n","1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n","2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n","3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n","4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n","\n","        V26       V27       V28  Amount  Class  \n","0 -0.189115  0.133558 -0.021053  149.62    0.0  \n","1  0.125895 -0.008983  0.014724    2.69    0.0  \n","2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n","3 -0.221929  0.062723  0.061458  123.50    0.0  \n","4  0.502292  0.219422  0.215153   69.99    0.0  \n","\n","[5 rows x 31 columns]\n","\n","Tail of the dataset:\n","       Time        V1        V2        V3        V4        V5        V6  \\\n","7968  10980  1.284388 -0.013181  0.646174  0.198985 -0.568675 -0.526121   \n","7969  10981  1.190428 -0.122329  0.954945  0.267101 -0.971026 -0.652279   \n","7970  10981 -0.725175  0.298202  1.824761 -2.587170  0.283605 -0.016617   \n","7971  10981  1.226153 -0.129645  0.735197  0.142752 -0.703245 -0.349641   \n","7972  10981  1.145381 -0.059349  0.968088  0.267891 -0.822582 -0.597727   \n","\n","            V7        V8        V9  ...       V21       V22       V23  \\\n","7968 -0.448235 -0.167709  1.773223  ... -0.101868 -0.030298 -0.081412   \n","7969 -0.612992 -0.003909  1.633117  ... -0.015001  0.127027  0.012079   \n","7970  0.153659  0.045084 -0.197611  ... -0.017097 -0.070535 -0.442861   \n","7971 -0.612641  0.020507  1.648986  ... -0.047936  0.040196 -0.057391   \n","7972 -0.450197 -0.119747  1.338188  ...       NaN       NaN       NaN   \n","\n","           V24       V25       V26       V27       V28  Amount  Class  \n","7968 -0.123281  0.278808  1.064001 -0.090181  0.000481   15.95    0.0  \n","7969  0.534409  0.112179  1.004483 -0.100188 -0.004774   14.95    0.0  \n","7970 -0.895837  0.624743 -0.510601 -0.031142  0.025564   12.95    0.0  \n","7971 -0.012386  0.187685  1.037786 -0.100081 -0.009869   15.95    0.0  \n","7972       NaN       NaN       NaN       NaN       NaN     NaN    NaN  \n","\n","[5 rows x 31 columns]\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import pandas as pd\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Assuming your credit card dataset is stored in a file named 'credit_card.csv'\n","file_path = '/content/drive/My Drive/path/to/your/dataset/credit_card.csv'\n","\n","# Read the CSV file into a DataFrame\n","df = pd.read_csv('/content/creditcard.csv')\n","\n","# Display the head of the dataset\n","print(\"Head of the dataset:\")\n","print(df.head())\n","\n","# Display the tail of the dataset\n","print(\"\\nTail of the dataset:\")\n","print(df.tail())\n","\n","# Split the data into features (X) and target variable (y)\n","X = df.drop('Class', axis=1)  # Features\n","y = df['Class']               # Target variable\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Initialize the Random Forest model\n","random_forest_model = RandomForestClassifier(random_state=42)\n","\n","# Train the model on the training set\n","random_forest_model.fit(X_train, y_train)\n","\n","# Make predictions on the testing set\n","y_pred = random_forest_model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","classification_rep = classification_report(y_test, y_pred)\n","\n","# Display the results\n","print(f\"Accuracy: {accuracy}\")\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n","print(\"\\nClassification Report:\")\n","print(classification_rep)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"RkmURLAZsUKn","executionInfo":{"status":"error","timestamp":1701793993828,"user_tz":-330,"elapsed":7392,"user":{"displayName":"meghshyam karpe","userId":"02298623278313287783"}},"outputId":"6c30ac73-15f1-4d41-bbce-a95258bb2d8f"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Head of the dataset:\n","   Time        V1        V2        V3        V4        V5        V6        V7  \\\n","0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n","1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n","2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n","3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n","4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n","\n","         V8        V9  ...       V21       V22       V23       V24       V25  \\\n","0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n","1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n","2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n","3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n","4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n","\n","        V26       V27       V28  Amount  Class  \n","0 -0.189115  0.133558 -0.021053  149.62    0.0  \n","1  0.125895 -0.008983  0.014724    2.69    0.0  \n","2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n","3 -0.221929  0.062723  0.061458  123.50    0.0  \n","4  0.502292  0.219422  0.215153   69.99    0.0  \n","\n","[5 rows x 31 columns]\n","\n","Tail of the dataset:\n","       Time        V1        V2        V3        V4        V5        V6  \\\n","7968  10980  1.284388 -0.013181  0.646174  0.198985 -0.568675 -0.526121   \n","7969  10981  1.190428 -0.122329  0.954945  0.267101 -0.971026 -0.652279   \n","7970  10981 -0.725175  0.298202  1.824761 -2.587170  0.283605 -0.016617   \n","7971  10981  1.226153 -0.129645  0.735197  0.142752 -0.703245 -0.349641   \n","7972  10981  1.145381 -0.059349  0.968088  0.267891 -0.822582 -0.597727   \n","\n","            V7        V8        V9  ...       V21       V22       V23  \\\n","7968 -0.448235 -0.167709  1.773223  ... -0.101868 -0.030298 -0.081412   \n","7969 -0.612992 -0.003909  1.633117  ... -0.015001  0.127027  0.012079   \n","7970  0.153659  0.045084 -0.197611  ... -0.017097 -0.070535 -0.442861   \n","7971 -0.612641  0.020507  1.648986  ... -0.047936  0.040196 -0.057391   \n","7972 -0.450197 -0.119747  1.338188  ...       NaN       NaN       NaN   \n","\n","           V24       V25       V26       V27       V28  Amount  Class  \n","7968 -0.123281  0.278808  1.064001 -0.090181  0.000481   15.95    0.0  \n","7969  0.534409  0.112179  1.004483 -0.100188 -0.004774   14.95    0.0  \n","7970 -0.895837  0.624743 -0.510601 -0.031142  0.025564   12.95    0.0  \n","7971 -0.012386  0.187685  1.037786 -0.100081 -0.009869   15.95    0.0  \n","7972       NaN       NaN       NaN       NaN       NaN     NaN    NaN  \n","\n","[5 rows x 31 columns]\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-0e54906a3bbd>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Make predictions on the testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \"\"\"\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    600\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    601\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Assuming your credit card dataset is stored in a file named 'credit_card.csv'\n","file_path = '/content/drive/My Drive/path/to/your/dataset/credit_card.csv'\n","\n","# Read the CSV file into a DataFrame\n","df = pd.read_csv('/content/creditcard.csv')\n","\n","# Display the head of the dataset\n","print(\"Head of the dataset:\")\n","print(df.head())\n","\n","# Display the tail of the dataset\n","print(\"\\nTail of the dataset:\")\n","print(df.tail())\n","\n","# Split the data into features (X) and target variable (y)\n","X = df.drop('Class', axis=1)  # Features\n","y = df['Class']               # Target variable\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Initialize the Random Forest model\n","random_forest_model = RandomForestClassifier(random_state=42)\n","\n","# Train the model on the training set\n","random_forest_model.fit(X_train, y_train)\n","\n","# Make predictions on the testing set\n","y_pred = random_forest_model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","classification_rep = classification_report(y_test, y_pred)\n"],"metadata":{"id":"8SgcvcOzujqN","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1701794120888,"user_tz":-330,"elapsed":7896,"user":{"displayName":"meghshyam karpe","userId":"02298623278313287783"}},"outputId":"373d3624-ab98-49bf-9a7c-032b153a2e03"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Head of the dataset:\n","   Time        V1        V2        V3        V4        V5        V6        V7  \\\n","0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n","1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n","2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n","3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n","4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n","\n","         V8        V9  ...       V21       V22       V23       V24       V25  \\\n","0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n","1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n","2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n","3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n","4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n","\n","        V26       V27       V28  Amount  Class  \n","0 -0.189115  0.133558 -0.021053  149.62    0.0  \n","1  0.125895 -0.008983  0.014724    2.69    0.0  \n","2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n","3 -0.221929  0.062723  0.061458  123.50    0.0  \n","4  0.502292  0.219422  0.215153   69.99    0.0  \n","\n","[5 rows x 31 columns]\n","\n","Tail of the dataset:\n","       Time        V1        V2        V3        V4        V5        V6  \\\n","7968  10980  1.284388 -0.013181  0.646174  0.198985 -0.568675 -0.526121   \n","7969  10981  1.190428 -0.122329  0.954945  0.267101 -0.971026 -0.652279   \n","7970  10981 -0.725175  0.298202  1.824761 -2.587170  0.283605 -0.016617   \n","7971  10981  1.226153 -0.129645  0.735197  0.142752 -0.703245 -0.349641   \n","7972  10981  1.145381 -0.059349  0.968088  0.267891 -0.822582 -0.597727   \n","\n","            V7        V8        V9  ...       V21       V22       V23  \\\n","7968 -0.448235 -0.167709  1.773223  ... -0.101868 -0.030298 -0.081412   \n","7969 -0.612992 -0.003909  1.633117  ... -0.015001  0.127027  0.012079   \n","7970  0.153659  0.045084 -0.197611  ... -0.017097 -0.070535 -0.442861   \n","7971 -0.612641  0.020507  1.648986  ... -0.047936  0.040196 -0.057391   \n","7972 -0.450197 -0.119747  1.338188  ...       NaN       NaN       NaN   \n","\n","           V24       V25       V26       V27       V28  Amount  Class  \n","7968 -0.123281  0.278808  1.064001 -0.090181  0.000481   15.95    0.0  \n","7969  0.534409  0.112179  1.004483 -0.100188 -0.004774   14.95    0.0  \n","7970 -0.895837  0.624743 -0.510601 -0.031142  0.025564   12.95    0.0  \n","7971 -0.012386  0.187685  1.037786 -0.100081 -0.009869   15.95    0.0  \n","7972       NaN       NaN       NaN       NaN       NaN     NaN    NaN  \n","\n","[5 rows x 31 columns]\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-89038399b2ba>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Make predictions on the testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \"\"\"\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    600\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    601\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Assuming your credit card dataset is stored in a file named 'credit_card.csv'\n","file_path = '/content/drive/My Drive/path/to/your/dataset/credit_card.csv'\n","\n","# Read the CSV file into a DataFrame\n","df = pd.read_csv('/content/creditcard.csv')\n","\n","# Display the head of the dataset\n","print(\"Head of the dataset:\")\n","print(df.head())\n","\n","# Display the tail of the dataset\n","print(\"\\nTail of the dataset:\")\n","print(df.tail())\n","\n","# Split the data into features (X) and target variable (y)\n","X = df.drop('Class', axis=1)  # Features\n","y = df['Class']               # Target variable\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Initialize the Random Forest model\n","random_forest_model = RandomForestClassifier(random_state=42)\n","\n","# Train the model on the training set\n","random_forest_model.fit(X_train, y_train)\n","\n","# Additional checks before making predictions\n","if X_test.isnull().sum().sum() > 0:\n","    print(\"Warning: Test set contains missing values.\")\n","\n","# Make predictions on the testing set\n","y_pred = random_forest_model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","classification_rep = classification_report(y_test, y_pred)\n","\n","# Print the evaluation metrics\n","print(\"Accuracy:\", accuracy)\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n","print(\"\\nClassification Report:\")\n","print(classification_rep)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xTF-9sY610IE","executionInfo":{"status":"error","timestamp":1701794285983,"user_tz":-330,"elapsed":10104,"user":{"displayName":"meghshyam karpe","userId":"02298623278313287783"}},"outputId":"c4c38814-efc0-454d-bb57-18891a584f0b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Head of the dataset:\n","   Time        V1        V2        V3        V4        V5        V6        V7  \\\n","0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n","1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n","2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n","3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n","4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n","\n","         V8        V9  ...       V21       V22       V23       V24       V25  \\\n","0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n","1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n","2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n","3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n","4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n","\n","        V26       V27       V28  Amount  Class  \n","0 -0.189115  0.133558 -0.021053  149.62    0.0  \n","1  0.125895 -0.008983  0.014724    2.69    0.0  \n","2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n","3 -0.221929  0.062723  0.061458  123.50    0.0  \n","4  0.502292  0.219422  0.215153   69.99    0.0  \n","\n","[5 rows x 31 columns]\n","\n","Tail of the dataset:\n","       Time        V1        V2        V3        V4        V5        V6  \\\n","7968  10980  1.284388 -0.013181  0.646174  0.198985 -0.568675 -0.526121   \n","7969  10981  1.190428 -0.122329  0.954945  0.267101 -0.971026 -0.652279   \n","7970  10981 -0.725175  0.298202  1.824761 -2.587170  0.283605 -0.016617   \n","7971  10981  1.226153 -0.129645  0.735197  0.142752 -0.703245 -0.349641   \n","7972  10981  1.145381 -0.059349  0.968088  0.267891 -0.822582 -0.597727   \n","\n","            V7        V8        V9  ...       V21       V22       V23  \\\n","7968 -0.448235 -0.167709  1.773223  ... -0.101868 -0.030298 -0.081412   \n","7969 -0.612992 -0.003909  1.633117  ... -0.015001  0.127027  0.012079   \n","7970  0.153659  0.045084 -0.197611  ... -0.017097 -0.070535 -0.442861   \n","7971 -0.612641  0.020507  1.648986  ... -0.047936  0.040196 -0.057391   \n","7972 -0.450197 -0.119747  1.338188  ...       NaN       NaN       NaN   \n","\n","           V24       V25       V26       V27       V28  Amount  Class  \n","7968 -0.123281  0.278808  1.064001 -0.090181  0.000481   15.95    0.0  \n","7969  0.534409  0.112179  1.004483 -0.100188 -0.004774   14.95    0.0  \n","7970 -0.895837  0.624743 -0.510601 -0.031142  0.025564   12.95    0.0  \n","7971 -0.012386  0.187685  1.037786 -0.100081 -0.009869   15.95    0.0  \n","7972       NaN       NaN       NaN       NaN       NaN     NaN    NaN  \n","\n","[5 rows x 31 columns]\n","Warning: Test set contains missing values.\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-00d5a417db25>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Make predictions on the testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \"\"\"\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    600\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    601\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Assuming your credit card dataset is stored in a file named 'credit_card.csv'\n","file_path = '/content/drive/My Drive/path/to/your/dataset/credit_card.csv'\n","\n","# Read the CSV file into a DataFrame\n","df = pd.read_csv('/content/creditcard.csv')\n","\n","# Display the head of the dataset\n","print(\"Head of the dataset:\")\n","print(df.head())\n","\n","# Display the tail of the dataset\n","print(\"\\nTail of the dataset:\")\n","print(df.tail())\n","\n","# Split the data into features (X) and target variable (y)\n","X = df.drop('Class', axis=1)  # Features\n","y = df['Class']               # Target variable\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Handle missing values in the test set\n","X_test = X_test.fillna(X_train.mean())  # You can use different imputation strategies based on your data\n","\n","# Initialize the Random Forest model\n","random_forest_model = RandomForestClassifier(random_state=42)\n","\n","# Train the model on the training set\n","random_forest_model.fit(X_train, y_train)\n","\n","# Make predictions on the testing set\n","y_pred = random_forest_model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(X_test, y_pred)\n","conf_matrix = confusion_matrix(X_test, y_pred)\n","classification_rep = classification_report(X_test_test, y_pred)\n","\n","# Print the evaluation metrics\n","print(\"Accuracy:\", accuracy)\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n","print(\"\\nClassification Report:\")\n","print(classification_rep)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2zBcKbZ82jPe","executionInfo":{"status":"error","timestamp":1701794612785,"user_tz":-330,"elapsed":8431,"user":{"displayName":"meghshyam karpe","userId":"02298623278313287783"}},"outputId":"65b2c036-5419-42f2-8b9e-1fca88756914"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Head of the dataset:\n","   Time        V1        V2        V3        V4        V5        V6        V7  \\\n","0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n","1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n","2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n","3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n","4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n","\n","         V8        V9  ...       V21       V22       V23       V24       V25  \\\n","0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n","1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n","2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n","3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n","4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n","\n","        V26       V27       V28  Amount  Class  \n","0 -0.189115  0.133558 -0.021053  149.62    0.0  \n","1  0.125895 -0.008983  0.014724    2.69    0.0  \n","2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n","3 -0.221929  0.062723  0.061458  123.50    0.0  \n","4  0.502292  0.219422  0.215153   69.99    0.0  \n","\n","[5 rows x 31 columns]\n","\n","Tail of the dataset:\n","       Time        V1        V2        V3        V4        V5        V6  \\\n","7968  10980  1.284388 -0.013181  0.646174  0.198985 -0.568675 -0.526121   \n","7969  10981  1.190428 -0.122329  0.954945  0.267101 -0.971026 -0.652279   \n","7970  10981 -0.725175  0.298202  1.824761 -2.587170  0.283605 -0.016617   \n","7971  10981  1.226153 -0.129645  0.735197  0.142752 -0.703245 -0.349641   \n","7972  10981  1.145381 -0.059349  0.968088  0.267891 -0.822582 -0.597727   \n","\n","            V7        V8        V9  ...       V21       V22       V23  \\\n","7968 -0.448235 -0.167709  1.773223  ... -0.101868 -0.030298 -0.081412   \n","7969 -0.612992 -0.003909  1.633117  ... -0.015001  0.127027  0.012079   \n","7970  0.153659  0.045084 -0.197611  ... -0.017097 -0.070535 -0.442861   \n","7971 -0.612641  0.020507  1.648986  ... -0.047936  0.040196 -0.057391   \n","7972 -0.450197 -0.119747  1.338188  ...       NaN       NaN       NaN   \n","\n","           V24       V25       V26       V27       V28  Amount  Class  \n","7968 -0.123281  0.278808  1.064001 -0.090181  0.000481   15.95    0.0  \n","7969  0.534409  0.112179  1.004483 -0.100188 -0.004774   14.95    0.0  \n","7970 -0.895837  0.624743 -0.510601 -0.031142  0.025564   12.95    0.0  \n","7971 -0.012386  0.187685  1.037786 -0.100081 -0.009869   15.95    0.0  \n","7972       NaN       NaN       NaN       NaN       NaN     NaN    NaN  \n","\n","[5 rows x 31 columns]\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-c923cf1cf933>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mclassification_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and binary targets"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Assuming your credit card dataset is stored in a file named 'credit_card.csv'\n","file_path = '/content/drive/My Drive/path/to/your/dataset/credit_card.csv'\n","\n","# Read the CSV file into a DataFrame\n","df = pd.read_csv('/content/creditcard.csv')\n","\n","# Display the head of the dataset\n","print(\"Head of the dataset:\")\n","print(df.head())\n","\n","# Display the tail of the dataset\n","print(\"\\nTail of the dataset:\")\n","print(df.tail())\n","\n","# Split the data into features (X) and target variable (y)\n","X = df.drop('Class', axis=1)  # Features\n","y = df['Class']               # Target variable\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Handle missing values in the test set\n","X_test = X_test.fillna(X_train.mean())  # You can use different imputation strategies based on your data\n","\n","# Initialize the Random Forest model\n","random_forest_model = RandomForestClassifier(random_state=42)\n","\n","# Train the model on the training set\n","random_forest_model.fit(X_train, y_train)\n","# Convert the target variable to binary if it's not already\n","y_test_binary = (y_test > 0.5).astype(int)\n","\n","# Make predictions on the testing set\n","y_pred = random_forest_model.predict(X_test)\n","\n","# Convert predicted values to binary\n","y_pred_binary = (y_pred > 0.5).astype(int)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test_binary, y_pred_binary)\n","conf_matrix = confusion_matrix(y_test_binary, y_pred_binary)\n","classification_rep = classification_report(y_test_binary, y_pred_binary)\n","\n","# Print the evaluation metrics\n","print(\"Accuracy:\", accuracy)\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n","print(\"\\nClassification Report:\")\n","print(classification_rep)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6lh3G7n57o1","executionInfo":{"status":"ok","timestamp":1701795368532,"user_tz":-330,"elapsed":9621,"user":{"displayName":"meghshyam karpe","userId":"02298623278313287783"}},"outputId":"ae3d27a9-ffa6-4125-bf2c-2366ee19fbbf"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Head of the dataset:\n","   Time        V1        V2        V3        V4        V5        V6        V7  \\\n","0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n","1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n","2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n","3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n","4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n","\n","         V8        V9  ...       V21       V22       V23       V24       V25  \\\n","0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n","1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n","2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n","3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n","4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n","\n","        V26       V27       V28  Amount  Class  \n","0 -0.189115  0.133558 -0.021053  149.62    0.0  \n","1  0.125895 -0.008983  0.014724    2.69    0.0  \n","2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n","3 -0.221929  0.062723  0.061458  123.50    0.0  \n","4  0.502292  0.219422  0.215153   69.99    0.0  \n","\n","[5 rows x 31 columns]\n","\n","Tail of the dataset:\n","       Time        V1        V2        V3        V4        V5        V6  \\\n","7968  10980  1.284388 -0.013181  0.646174  0.198985 -0.568675 -0.526121   \n","7969  10981  1.190428 -0.122329  0.954945  0.267101 -0.971026 -0.652279   \n","7970  10981 -0.725175  0.298202  1.824761 -2.587170  0.283605 -0.016617   \n","7971  10981  1.226153 -0.129645  0.735197  0.142752 -0.703245 -0.349641   \n","7972  10981  1.145381 -0.059349  0.968088  0.267891 -0.822582 -0.597727   \n","\n","            V7        V8        V9  ...       V21       V22       V23  \\\n","7968 -0.448235 -0.167709  1.773223  ... -0.101868 -0.030298 -0.081412   \n","7969 -0.612992 -0.003909  1.633117  ... -0.015001  0.127027  0.012079   \n","7970  0.153659  0.045084 -0.197611  ... -0.017097 -0.070535 -0.442861   \n","7971 -0.612641  0.020507  1.648986  ... -0.047936  0.040196 -0.057391   \n","7972 -0.450197 -0.119747  1.338188  ...       NaN       NaN       NaN   \n","\n","           V24       V25       V26       V27       V28  Amount  Class  \n","7968 -0.123281  0.278808  1.064001 -0.090181  0.000481   15.95    0.0  \n","7969  0.534409  0.112179  1.004483 -0.100188 -0.004774   14.95    0.0  \n","7970 -0.895837  0.624743 -0.510601 -0.031142  0.025564   12.95    0.0  \n","7971 -0.012386  0.187685  1.037786 -0.100081 -0.009869   15.95    0.0  \n","7972       NaN       NaN       NaN       NaN       NaN     NaN    NaN  \n","\n","[5 rows x 31 columns]\n","Accuracy: 1.0\n","\n","Confusion Matrix:\n","[[2390    0]\n"," [   0    2]]\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      2390\n","           1       1.00      1.00      1.00         2\n","\n","    accuracy                           1.00      2392\n","   macro avg       1.00      1.00      1.00      2392\n","weighted avg       1.00      1.00      1.00      2392\n","\n"]}]}]}